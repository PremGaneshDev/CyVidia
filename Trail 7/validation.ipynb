{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 20:51:01.227440: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "# Load your Excel files for validation\n",
    "validation_file_path = '/Users/PremGanesh/Developer/Cyvidia/CyVidia/Input_Data/Validation Dataset.xlsx'\n",
    "validation_df = pd.read_excel(validation_file_path)\n",
    "# Define input and output file paths\n",
    "input_file_path = '/Users/PremGanesh/Developer/Cyvidia/CyVidia/Output_Data/mlv.xlsx'\n",
    "output_file_path = '/Users/PremGanesh/Developer/Cyvidia/CyVidia/Output_Data/mlv_validation2.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "# Load the saved tokenizer using pickle\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4\n",
    "# Load the encoders from the training process\n",
    "with open('area_encoder.pickle', 'rb') as handle:\n",
    "    area_encoder = pickle.load(handle)\n",
    "with open('bucket_encoder.pickle', 'rb') as handle:\n",
    "    bucket_encoder = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 5\n",
    "# Define a function for text cleaning\n",
    "def clean_text(text):\n",
    "    if isinstance(text, float) and np.isnan(text):\n",
    "        return \"\"\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.isalnum()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    clean_text = ' '.join(words)\n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6\n",
    "# Apply text cleaning to 'Requirement Description' column for validation data\n",
    "validation_df['Cleaned_Description'] = validation_df['Requirement Description'].apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7\n",
    "# Tokenize and pad sequences for validation data\n",
    "max_words = 1000\n",
    "X_val = tokenizer.texts_to_sequences(validation_df['Cleaned_Description'])\n",
    "X_val = pad_sequences(X_val, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8\n",
    "# Load the saved model\n",
    "loaded_model = load_model('trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "# Cell 9\n",
    "# Predict on validation data using the loaded model\n",
    "y_pred = loaded_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10\n",
    "# Get prediction scores for 'Area' and 'Bucket'\n",
    "prediction_scores_area = np.max(y_pred[0], axis=1)\n",
    "prediction_scores_bucket = np.max(y_pred[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11\n",
    "# Add the prediction scores to the validation DataFrame\n",
    "validation_df['Prediction_Score_Area'] = prediction_scores_area\n",
    "validation_df['Prediction_Score_Bucket'] = prediction_scores_bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12\n",
    "# Define a labeling threshold (e.g., 0.85)\n",
    "labeling_threshold = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13\n",
    "# Initialize lists to store predicted labels and suggested labels\n",
    "predicted_labels_area = []\n",
    "suggested_labels_area = []\n",
    "predicted_labels_bucket = []\n",
    "suggested_labels_bucket = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14\n",
    "# Iterate through predictions and apply labeling/suggestion logic\n",
    "for pred_area, score_area, pred_bucket, score_bucket in zip(\n",
    "    np.argmax(y_pred[0], axis=1),\n",
    "    prediction_scores_area,\n",
    "    np.argmax(y_pred[1], axis=1),\n",
    "    prediction_scores_bucket\n",
    "):\n",
    "    if score_area >= labeling_threshold:\n",
    "        predicted_labels_area.append(area_encoder.inverse_transform([pred_area])[0])\n",
    "        suggested_labels_area.append('')\n",
    "    else:\n",
    "        predicted_labels_area.append('Other')\n",
    "        suggested_labels_area.append(area_encoder.inverse_transform([pred_area])[0])\n",
    "\n",
    "    if score_bucket >= labeling_threshold:\n",
    "        predicted_labels_bucket.append(bucket_encoder.inverse_transform([pred_bucket])[0])\n",
    "        suggested_labels_bucket.append('')\n",
    "    else:\n",
    "        predicted_labels_bucket.append('Other')\n",
    "        suggested_labels_bucket.append(bucket_encoder.inverse_transform([pred_bucket])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15\n",
    "# Add the predicted labels and suggested labels to the validation DataFrame\n",
    "validation_df['Predicted_Area'] = predicted_labels_area\n",
    "validation_df['Suggested_Area'] = suggested_labels_area\n",
    "validation_df['Predicted_Bucket'] = predicted_labels_bucket\n",
    "validation_df['Suggested_Bucket'] = suggested_labels_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results with predicted/suggested labels and scores saved to /Users/PremGanesh/Developer/Cyvidia/CyVidia/Output_Data/mlv.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 16\n",
    "# Save the validation results DataFrame to an Excel file\n",
    "validation_results_file_path = '/Users/PremGanesh/Developer/Cyvidia/CyVidia/Output_Data/mlv.xlsx'\n",
    "validation_df.to_excel(validation_results_file_path, index=False)\n",
    "print(\"Validation results with predicted/suggested labels and scores saved to\", validation_results_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names\n",
    "req_no_col = 'ReqNo'\n",
    "req_area_col = 'Requirement Area'\n",
    "req_area_nist_col = 'Requirement Area (NIST)'\n",
    "req_bucket_nist_col = 'Requirement Bucket(NIST)'\n",
    "\n",
    "key_words_col = 'Key Words'\n",
    "type_col = 'Type'\n",
    "source_type_col = 'Source Type'\n",
    "source_col = 'Source'\n",
    "source_detail_col = 'Source Detail'\n",
    "source_req_id_col = 'Source Requirement ID#'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "df = pd.read_excel(input_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predicted_area into lower case\n",
    "df['Requirement Area (NIST)'] = df['Requirement Area (NIST)'].str.lower()\n",
    "df['Requirement Bucket(NIST)'] = df['Requirement Bucket(NIST)'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate validation\n",
    "def calculate_validation(row):\n",
    "    # if predicted area is other then check with suggested area with nist area\n",
    "    if row['Predicted_Area'] == 'Other':\n",
    "        if row['Suggested_Area'] == row[req_area_nist_col]:\n",
    "            area_validation = 'Correct'\n",
    "        elif pd.isna(row['Suggested_Area']):\n",
    "            area_validation = 'Empty'\n",
    "        else:\n",
    "            area_validation = 'Incorrect'\n",
    "    if pd.notna(row['Predicted_Area']) and row['Predicted_Area'] == row[req_area_nist_col]:\n",
    "        area_validation = 'Correct'\n",
    "    elif pd.isna(row['Predicted_Area']):\n",
    "        area_validation = 'Empty'\n",
    "    else:\n",
    "        area_validation = 'Incorrect'\n",
    "\n",
    "    if pd.notna(row['Predicted_Bucket']) and row['Predicted_Bucket'] == row[req_bucket_nist_col]:\n",
    "        bucket_validation = 'Correct'\n",
    "    elif pd.isna(row['Predicted_Bucket']):\n",
    "        bucket_validation = 'Empty'\n",
    "    else:\n",
    "        bucket_validation = 'Incorrect'\n",
    "\n",
    "    return area_validation, bucket_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to create new columns\n",
    "df['Area Validation'], df['Bucket Validation'] = zip(*df.apply(calculate_validation, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate counts for 'Area Validation' and 'Bucket Validation'\n",
    "area_validation_counts = df['Area Validation'].value_counts()\n",
    "bucket_validation_counts = df['Bucket Validation'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentages for 'Area Validation Accuracy' and 'Bucket Validation Accuracy'\n",
    "area_validation_accuracy = (area_validation_counts.get('Correct', 0) / (area_validation_counts.sum())) * 100\n",
    "bucket_validation_accuracy = (bucket_validation_counts.get('Correct', 0) / (bucket_validation_counts.sum())) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the counts and percentages\n",
    "validation_summary = {\n",
    "    'Total Count': len(df),\n",
    "    'Area Validation Correct Count': area_validation_counts.get('Correct', 0),\n",
    "    'Area Validation Incorrect Count': area_validation_counts.get('Incorrect', 0),\n",
    "    'Area Validation Empty Count': area_validation_counts.get('Empty', 0),\n",
    "    'Bucket Validation Correct Count': bucket_validation_counts.get('Correct', 0),\n",
    "    'Bucket Validation Incorrect Count': bucket_validation_counts.get('Incorrect', 0),\n",
    "    'Bucket Validation Empty Count': bucket_validation_counts.get('Empty', 0),\n",
    "    'Area Validation Accuracy': area_validation_accuracy,\n",
    "    'Bucket Validation Accuracy': bucket_validation_accuracy\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do analysis on the validation summary which are correctly mapped and which are wrongly mapped\n",
    "df_correct = df[(df['Area Validation'] == 'Correct') & (df['Bucket Validation'] == 'Correct')]\n",
    "df_incorrect = df[(df['Area Validation'] == 'Incorrect') | (df['Bucket Validation'] == 'Incorrect')]\n",
    "df_empty = df[(df['Area Validation'] == 'Empty') | (df['Bucket Validation'] == 'Empty')]\n",
    "# add plot for the validation summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary to a DataFrame and transpose it\n",
    "summary_df = pd.DataFrame(validation_summary, index=[0]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "summary_df = summary_df.reset_index()\n",
    "# Rename the columns\n",
    "summary_df.columns = ['Validation Metric', 'Count']\n",
    "# Append the summary DataFrame to the original DataFrame\n",
    "df = pd.concat([df, summary_df], ignore_index=True)\n",
    "# Drop specified columns\n",
    "columns_to_remove = [req_no_col, req_area_col, 'Requirements Bucket','Cleaned_Description' , key_words_col, type_col, source_type_col, source_col, source_detail_col, source_req_id_col]\n",
    "df = df.drop(columns=columns_to_remove)\n",
    "# Save the DataFrame to a new Excel file\n",
    "df.to_excel(output_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
